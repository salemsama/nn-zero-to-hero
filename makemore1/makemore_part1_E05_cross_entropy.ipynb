{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYrRBUbdDnJseCgeumhhBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salemsama/nn-zero-to-hero/blob/main/makemore1/makemore_part1_E05_cross_entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SbkLzBtVWOoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9b1f4cfc-15df-4483-a5b1-2ef304e7dbdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emma'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# E05: look up and use F.cross_entropy instead. You should achieve the same result.\n",
        "# Can you think of why we'd prefer to use F.cross_entropy instead?\n",
        "\n",
        "# result:\n",
        "# achieve the same thing\n",
        "# I think we'd prefer it becuase its already exist function that is opitmized for this job wich mean it would do more efficently\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "words = open(\"names.txt\", 'r').read().splitlines()\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "words[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is trigram and exercise on bigram\n",
        "# nerualnetwork version\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for w in words:\n",
        "  #we add 2 dots because we need a context (learned this idea from the video after this aka makemore 2)\n",
        "  chs = ['.','.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    xs.append(stoi[ch1]*27 + stoi[ch2])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "\n",
        "print(f\"xs: {xs} \\nys: {ys}\")\n",
        "\n",
        "#P = (N+1).float()\n",
        "#P /= P.sum(1, keepdims=True)\n",
        "#g = torch.Generator().manual_seed(2147483647)"
      ],
      "metadata": {
        "id": "aI39EenlWwZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e918ce-2db1-4c7b-8d50-da1cde0cf280"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xs: tensor([  0,   5, 148,  ..., 727, 701, 726]) \n",
            "ys: tensor([ 5, 13, 13,  ..., 26, 24,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encodeing xs\n",
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes = 729).float() # 729 = 27 * 27 because we have 2 chars"
      ],
      "metadata": {
        "id": "KCNnmVACxXbw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLOnUZPRyO42",
        "outputId": "af849d67-4a96-4df8-b9bc-bc2654f11544"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.shape # n * 729 where n is number of input aka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cALBZ02Tyu_4",
        "outputId": "cf9c91ba-256a-4b71-a50d-e45c0058ea9e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 729])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initilize weights\n",
        "gen = torch.Generator().manual_seed(2147483647)\n",
        "w = torch.randn((729,27), generator=gen, requires_grad=True)"
      ],
      "metadata": {
        "id": "UuNuCl0CzAIS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  # forward pass\n",
        "  logits = w[xs]     #xenc @ w\n",
        "  loss = F.cross_entropy(logits,ys, label_smoothing=0.001)\n",
        "  # backward pass\n",
        "  w.grad = None # zero grad\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  w.data += -10 * w.grad\n",
        "  print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJihYiBY1f18",
        "outputId": "1f5bb11e-ef00-454f-8fc8-aa55a5659d47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2991600036621094\n",
            "2.2991139888763428\n",
            "2.2990684509277344\n",
            "2.299022674560547\n",
            "2.2989768981933594\n",
            "2.298931360244751\n",
            "2.2988855838775635\n",
            "2.298840284347534\n",
            "2.2987945079803467\n",
            "2.2987494468688965\n",
            "2.298703670501709\n",
            "2.298658609390259\n",
            "2.2986130714416504\n",
            "2.298567771911621\n",
            "2.298522710800171\n",
            "2.2984771728515625\n",
            "2.298431873321533\n",
            "2.298386573791504\n",
            "2.298341989517212\n",
            "2.2982966899871826\n",
            "2.2982516288757324\n",
            "2.298206329345703\n",
            "2.2981619834899902\n",
            "2.298116683959961\n",
            "2.298072099685669\n",
            "2.2980270385742188\n",
            "2.2979822158813477\n",
            "2.2979373931884766\n",
            "2.2978928089141846\n",
            "2.2978482246398926\n",
            "2.2978034019470215\n",
            "2.2977590560913086\n",
            "2.2977144718170166\n",
            "2.2976696491241455\n",
            "2.2976255416870117\n",
            "2.2975807189941406\n",
            "2.2975363731384277\n",
            "2.297492027282715\n",
            "2.297447681427002\n",
            "2.297403335571289\n",
            "2.2973592281341553\n",
            "2.2973146438598633\n",
            "2.2972707748413086\n",
            "2.2972261905670166\n",
            "2.297182083129883\n",
            "2.297138214111328\n",
            "2.2970941066741943\n",
            "2.2970502376556396\n",
            "2.297006130218506\n",
            "2.296962261199951\n",
            "2.2969186305999756\n",
            "2.296874523162842\n",
            "2.296830654144287\n",
            "2.2967870235443115\n",
            "2.2967429161071777\n",
            "2.2966997623443604\n",
            "2.2966556549072266\n",
            "2.29661226272583\n",
            "2.2965686321258545\n",
            "2.296525001525879\n",
            "2.2964813709259033\n",
            "2.296438217163086\n",
            "2.2963945865631104\n",
            "2.296351194381714\n",
            "2.2963075637817383\n",
            "2.296264410018921\n",
            "2.2962212562561035\n",
            "2.296177864074707\n",
            "2.2961347103118896\n",
            "2.2960917949676514\n",
            "2.296048164367676\n",
            "2.2960052490234375\n",
            "2.29596209526062\n",
            "2.2959189414978027\n",
            "2.2958760261535645\n",
            "2.295833110809326\n",
            "2.295789957046509\n",
            "2.2957472801208496\n",
            "2.2957043647766113\n",
            "2.295661449432373\n",
            "2.295618772506714\n",
            "2.2955756187438965\n",
            "2.2955334186553955\n",
            "2.2954907417297363\n",
            "2.295447826385498\n",
            "2.295405387878418\n",
            "2.295362710952759\n",
            "2.2953197956085205\n",
            "2.2952775955200195\n",
            "2.2952353954315186\n",
            "2.2951929569244385\n",
            "2.2951505184173584\n",
            "2.2951080799102783\n",
            "2.2950656414031982\n",
            "2.2950236797332764\n",
            "2.2949812412261963\n",
            "2.294938802719116\n",
            "2.2948966026306152\n",
            "2.2948544025421143\n",
            "2.2948122024536133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKzq0AhDO-uz",
        "outputId": "4f173ec3-845f-474d-a5bc-e48904bb22b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.9721181392669678"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "    xenc = [ix1*27 + ix2]\n",
        "    xenc = F.one_hot(torch.tensor(xenc), num_classes=729).float()\n",
        "    logits = xenc @ w\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=gen).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "id": "U298DCiaXcYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68d2cda-cd1d-4496-ca6e-5518a5c0f141"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amega.\n",
            "chany.\n",
            "sufibxqdgkri.\n",
            "zieqilia.\n",
            "raanvinegnxiyah.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUSyphaiAZUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}