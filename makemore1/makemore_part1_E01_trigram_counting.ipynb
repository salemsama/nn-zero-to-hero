{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4Sqg+/RcBWy2OVkEolPME",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salemsama/nn-zero-to-hero/blob/main/makemore1/makemore_part1_E01_trigram_counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SbkLzBtVWOoD"
      },
      "outputs": [],
      "source": [
        "# E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one.\n",
        "# Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
        "\n",
        "# result:\n",
        "# Loss = 2.2119739055633545 compared to 2.476470470428467(karpathy) or in my case it was 2.5839083194732666\n",
        "# samples sounds more like names: junide. jakasid. prelay. adin. kairritoper.\n",
        "\n",
        "import torch\n",
        "N = torch.zeros((729, 27), dtype=torch.int32)\n",
        "\n",
        "words = open(\"names.txt\", 'r').read().splitlines()\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is trigram and exercise on bigram\n",
        "# counting version\n",
        "\n",
        "for w in words:\n",
        "  #we add 2 dots because we need a context (learned this idea from the video after this aka makemore 2)\n",
        "  chs = ['.','.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    N[ix1*27 + ix2, ix3] += 1\n",
        "\n",
        "P = (N+1).float()\n",
        "P /= P.sum(1, keepdims=True)\n",
        "g = torch.Generator().manual_seed(2147483647)"
      ],
      "metadata": {
        "id": "aI39EenlWwZR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "    p = P[ix1*27 + ix2]\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feMU4JouWrDL",
        "outputId": "9c368451-4bfc-4e70-c334-983329c22caf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "junide.\n",
            "jakasid.\n",
            "prelay.\n",
            "adin.\n",
            "kairritoper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate loss\n",
        "log_likelihood = 0.0\n",
        "n = 0\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.','.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    ix3 = stoi[ch3]\n",
        "    prob = P[ix1*27 + ix2, ix3]\n",
        "    logprob = torch.log(prob)\n",
        "    log_likelihood += logprob\n",
        "    n +=1\n",
        "\n",
        "print(f'{log_likelihood=}')\n",
        "nll = -log_likelihood\n",
        "print(f'{nll=}')\n",
        "print(f'{nll/n}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75tu1YTxWl09",
        "outputId": "03e8846d-b0b7-49e7-a7e5-f73f439ca153"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_likelihood=tensor(-504653.)\n",
            "nll=tensor(504653.)\n",
            "2.2119739055633545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U298DCiaXcYN"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}