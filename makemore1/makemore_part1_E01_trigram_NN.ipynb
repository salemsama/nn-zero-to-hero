{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8D4KW3gZk8zSNRDLnWiBX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salemsama/nn-zero-to-hero/blob/main/makemore1/makemore_part1_E01_trigram_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SbkLzBtVWOoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "902706df-9d48-4522-e47a-d6b5c100a839"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'emma'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# E01: train a trigram language model, i.e. take two characters as an input to predict the 3rd one.\n",
        "# Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?\n",
        "\n",
        "# result:\n",
        "# samples sound like: kellia. keon. elah. arkhwapcwwafyhcaifevina. lijamerele.\n",
        "# loss: 2.3537044525146484 , still doing progress in training but it takes too long\n",
        "\n",
        "import torch\n",
        "\n",
        "words = open(\"names.txt\", 'r').read().splitlines()\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "words[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is trigram and exercise on bigram\n",
        "# nerualnetwork version\n",
        "xs = []\n",
        "ys = []\n",
        "\n",
        "for w in words:\n",
        "  #we add 2 dots because we need a context (learned this idea from the video after this aka makemore 2)\n",
        "  chs = ['.','.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    xs.append(stoi[ch1]*27 + stoi[ch2])\n",
        "    ys.append(stoi[ch3])\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "\n",
        "print(f\"xs: {xs} \\nys: {ys}\")\n",
        "\n",
        "#P = (N+1).float()\n",
        "#P /= P.sum(1, keepdims=True)\n",
        "#g = torch.Generator().manual_seed(2147483647)"
      ],
      "metadata": {
        "id": "aI39EenlWwZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbcb0fc-825c-4967-96e9-9926602de04d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xs: tensor([  0,   5, 148,  ..., 727, 701, 726]) \n",
            "ys: tensor([ 5, 13, 13,  ..., 26, 24,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encodeing xs\n",
        "import torch.nn.functional as F\n",
        "xenc = F.one_hot(xs, num_classes = 729).float() # 729 = 27 * 27 because we have 2 chars"
      ],
      "metadata": {
        "id": "KCNnmVACxXbw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xenc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLOnUZPRyO42",
        "outputId": "0137ec2e-e0e1-4941-8024-b4f1fb5085a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.shape # n * 729 where n is number of input aka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cALBZ02Tyu_4",
        "outputId": "e809b042-fbc8-45c4-eaa9-2f90b33decf7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 729])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initilize weights\n",
        "gen = torch.Generator().manual_seed(2147483647)\n",
        "w = torch.randn((729,27), generator=gen, requires_grad=True)"
      ],
      "metadata": {
        "id": "UuNuCl0CzAIS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(100):\n",
        "  # forward pass\n",
        "  logits = xenc @ w\n",
        "  counts = logits.exp()\n",
        "  probs  = counts / counts.sum(1, keepdim=True)\n",
        "\n",
        "  loss = -probs[torch.arange(num), ys].log().mean()\n",
        "  # backward pass\n",
        "  w.grad = None # zero grad\n",
        "  loss.backward()\n",
        "\n",
        "  #update\n",
        "  w.data += -10 * w.grad\n",
        "  print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJihYiBY1f18",
        "outputId": "17fe0978-b1d6-42f6-cf59-36849509d8da"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.365194320678711\n",
            "2.36506986618042\n",
            "2.364945888519287\n",
            "2.364821672439575\n",
            "2.3646981716156006\n",
            "2.364574909210205\n",
            "2.3644514083862305\n",
            "2.364328145980835\n",
            "2.3642053604125977\n",
            "2.3640825748443604\n",
            "2.363959312438965\n",
            "2.3638370037078857\n",
            "2.3637146949768066\n",
            "2.3635926246643066\n",
            "2.363471031188965\n",
            "2.363348960876465\n",
            "2.363227605819702\n",
            "2.3631060123443604\n",
            "2.3629846572875977\n",
            "2.362863540649414\n",
            "2.3627426624298096\n",
            "2.362622022628784\n",
            "2.362501382827759\n",
            "2.3623812198638916\n",
            "2.3622608184814453\n",
            "2.362140655517578\n",
            "2.362020969390869\n",
            "2.361901044845581\n",
            "2.361781597137451\n",
            "2.3616621494293213\n",
            "2.3615431785583496\n",
            "2.3614237308502197\n",
            "2.361304998397827\n",
            "2.3611862659454346\n",
            "2.361067771911621\n",
            "2.3609492778778076\n",
            "2.3608312606811523\n",
            "2.360713005065918\n",
            "2.360595226287842\n",
            "2.3604774475097656\n",
            "2.3603599071502686\n",
            "2.3602423667907715\n",
            "2.3601253032684326\n",
            "2.3600082397460938\n",
            "2.359891414642334\n",
            "2.359774589538574\n",
            "2.3596582412719727\n",
            "2.359541654586792\n",
            "2.3594255447387695\n",
            "2.359309673309326\n",
            "2.3591933250427246\n",
            "2.3590779304504395\n",
            "2.358962059020996\n",
            "2.35884690284729\n",
            "2.358731269836426\n",
            "2.358616352081299\n",
            "2.358501434326172\n",
            "2.358386754989624\n",
            "2.358271837234497\n",
            "2.3581573963165283\n",
            "2.3580431938171387\n",
            "2.357928991317749\n",
            "2.3578150272369385\n",
            "2.357701301574707\n",
            "2.3575873374938965\n",
            "2.357473850250244\n",
            "2.357360601425171\n",
            "2.3572471141815186\n",
            "2.3571343421936035\n",
            "2.3570213317871094\n",
            "2.3569085597991943\n",
            "2.3567960262298584\n",
            "2.3566834926605225\n",
            "2.3565709590911865\n",
            "2.356459140777588\n",
            "2.356346845626831\n",
            "2.3562352657318115\n",
            "2.356123447418213\n",
            "2.3560121059417725\n",
            "2.355900764465332\n",
            "2.3557894229888916\n",
            "2.3556783199310303\n",
            "2.355567455291748\n",
            "2.355456590652466\n",
            "2.3553459644317627\n",
            "2.3552355766296387\n",
            "2.3551251888275146\n",
            "2.3550150394439697\n",
            "2.354904890060425\n",
            "2.354794979095459\n",
            "2.354685068130493\n",
            "2.3545756340026855\n",
            "2.354465961456299\n",
            "2.3543570041656494\n",
            "2.354248046875\n",
            "2.3541386127471924\n",
            "2.354029893875122\n",
            "2.353921413421631\n",
            "2.3538129329681396\n",
            "2.3537044525146484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKzq0AhDO-uz",
        "outputId": "ca0408fa-4a02-4989-a8c7-2bcc09f3bc9e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.785801887512207"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sampling\n",
        "for i in range(5):\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "    xenc = [ix1*27 + ix2]\n",
        "    xenc = F.one_hot(torch.tensor(xenc), num_classes=729).float()\n",
        "    logits = xenc @ w\n",
        "    counts = logits.exp()\n",
        "    p = counts / counts.sum(1, keepdims=True)\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=gen).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))\n"
      ],
      "metadata": {
        "id": "U298DCiaXcYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850240e6-54c3-44e2-8af6-767629f443eb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kellia.\n",
            "keon.\n",
            "elah.\n",
            "arkhwapcwwafyhcaifevina.\n",
            "lijamerele.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUSyphaiAZUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}